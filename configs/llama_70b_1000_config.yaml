# Configuration for 1,000 samples with Llama 3.1 70B
# Optimized for complex instruction following

# General settings
dataset_name: "Bingsu/openwebtext_20p"
num_samples: 1000
chunk_size: 500
max_tokens: 50
split: "train"
output_dir: "outputs"

# Model configuration - focused on capability
models:
  - name: "llama-3.1-70b-1000"
    model_id: "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"
    temperature: 0.7
    logprobs: 5

# Advanced settings
random_seed: 42
save_intermediate: true
verbose: true