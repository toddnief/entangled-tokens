together>=1.0.0
python-dotenv>=1.0.0
datasets>=2.16.0
transformers>=4.36.0
pyyaml>=6.0

# Local model support for A100
torch>=2.0.0
accelerate>=0.24.0
bitsandbytes>=0.41.0
scipy
safetensors
tokenizers

# Optional: vLLM for faster inference (A100 optimized)
# vllm>=0.2.2

# Progress bars and utilities
tqdm>=4.64.0
numpy>=1.21.0

# Unsloth for ultra-fast inference (A100 optimized)
unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git
xformers>=0.0.20
triton>=2.0.0
bitsandbytes>=0.41.0

# Additional Unsloth dependencies
ninja  # For faster compilation
einops>=0.6.0  # For tensor operations

# Optional: Flash Attention (install separately if CUDA issues)
# flash-attn>=2.0.0  # Commented out - can cause CUDA compilation issues